{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(180000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "%matplotlib tk\n",
    "#%matplotlib qt\n",
    "%autosave 180\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from pylab import specgram\n",
    "from scipy.signal import argrelmax\n",
    "from scipy.stats import linregress, pearsonr\n",
    "import os\n",
    "\n",
    "#%pylab inline\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_filter_data(fname, call_onset, call_offset, filter_data, plotting):\n",
    "\n",
    "    # load data\n",
    "    print (\"Loading: \", fname)\n",
    "    data = np.load(fname)\n",
    "    mic0_audio = data[0]\n",
    "    mic1_audio = data[1]\n",
    "    mic2_audio = data[2]\n",
    "    mic3_audio = data[3]\n",
    "    \n",
    "    # clip data \n",
    "    #print (\"Clipping :\", call_onset, call_offset)\n",
    "    fs = 250000\n",
    "    call_mic0 = mic0_audio[int(call_onset*fs):int(call_offset*fs)]\n",
    "    call_mic1 = mic1_audio[int(call_onset*fs):int(call_offset*fs)]\n",
    "    call_mic2 = mic2_audio[int(call_onset*fs):int(call_offset*fs)]\n",
    "    call_mic3 = mic3_audio[int(call_onset*fs):int(call_offset*fs)]  \n",
    "\n",
    "\n",
    "    nfft = 1024\n",
    "    if plotting:\n",
    "        fig=plt.figure()\n",
    "        ax1=plt.subplot(4,2,1)\n",
    "        pxx, freqs, bins, im = specgram(call_mic0, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "        plt.ylabel('mic 0')\n",
    "\n",
    "        ax1=plt.subplot(4,2,3)\n",
    "        pxx, freqs, bins, im = specgram(call_mic1, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "        plt.ylabel('mic 1')\n",
    "\n",
    "        ax1=plt.subplot(4,2,5)\n",
    "        pxx, freqs, bins, im = specgram(call_mic2, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "        plt.ylabel('mic 2')\n",
    "\n",
    "        ax1=plt.subplot(4,2,7)\n",
    "        pxx, freqs, bins, im = specgram(call_mic3, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "        plt.ylabel('mic 3')\n",
    "\n",
    "    # filter data\n",
    "    start_fs = 6500\n",
    "    end_fs = 7500\n",
    "    mic0_audio_bp = butter_bandpass_filter(call_mic0, start_fs, end_fs, fs)  # YOU CAN AUTODETECT THIS\n",
    "    mic1_audio_bp = butter_bandpass_filter(call_mic1, start_fs, end_fs, fs)\n",
    "    mic2_audio_bp = butter_bandpass_filter(call_mic2, start_fs, end_fs, fs)\n",
    "    mic3_audio_bp = butter_bandpass_filter(call_mic3, start_fs, end_fs, fs)\n",
    "\n",
    "    if plotting:\n",
    "        ax2=plt.subplot(4,2,2)\n",
    "        pxx, freqs, bins, im = specgram(mic0_audio_bp, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "\n",
    "        ax2=plt.subplot(4,2,4)\n",
    "        pxx, freqs, bins, im = specgram(mic1_audio_bp, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "\n",
    "        ax2=plt.subplot(4,2,6)\n",
    "        pxx, freqs, bins, im = specgram(mic2_audio_bp, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "\n",
    "        ax2=plt.subplot(4,2,8)\n",
    "        pxx, freqs, bins, im = specgram(mic3_audio_bp, NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-100,-80))\n",
    "        plt.ylim(0,40000)\n",
    "\n",
    "        plt.suptitle(os.path.split(fname)[1])\n",
    "    \n",
    "    if filter_data:\n",
    "        return (mic0_audio_bp, mic1_audio_bp, mic2_audio_bp, mic3_audio_bp)\n",
    "    else:\n",
    "        return (call_mic0, call_mic1, call_mic2, call_mic3)\n",
    "    \n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-15d481fcf175>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mvid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mctr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Load video file\n",
    "fname = \"/media/cat/4TBSSD/dan/july_19/2020_07_24_15_11_26_425064/video/2020_07_24_15_11_26_425064.avi\"\n",
    "\n",
    "fname_light = fname[:-4]+\"_light.npy\"\n",
    "fname_vid = fname[:-4]+\".npy\"\n",
    "if os.path.exists(fname_light)==False:\n",
    "    cap = cv2.VideoCapture(fname)\n",
    "\n",
    "    # make a downsampled version of the video; Even more should be ok\n",
    "    vid = np.zeros((30000,1024//4,1280//4,3),'uint8')\n",
    "\n",
    "    ctr=0\n",
    "    while(cap.isOpened()):\n",
    "        if ctr%1000==0:\n",
    "            print (ctr)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "        vid[ctr]=frame[::4,::4]\n",
    "        ctr+=1\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print (\"Video file: \", vid.shape)\n",
    "    # Find the pixel with LED light and track it's max over all 3 color channels over time\n",
    "    light = vid[:,147, 306].max(1)\n",
    "    print(light.shape)\n",
    "    np.save(fname_light, light)\n",
    "    np.save(fname_vid, vid)\n",
    "else:\n",
    "    light = np.load(fname_light)\n",
    "    vid = np.load(fname_vid)\n",
    "print (\"LED Light: \", light.shape)\n",
    "print (\"Vid: \", vid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio file:  (150000000,)\n"
     ]
    }
   ],
   "source": [
    "# Load audio file\n",
    "mic4 = np.load('/media/cat/4TBSSD/dan/july_19/2020_07_24_15_11_26_425064/audio/2020_07_24_15_11_26_425064_audio_mic_4.npy')\n",
    "print (\"audio file: \", mic4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data against each other OPTIONAL\n",
    "if False:\n",
    "    t_led = np.arange(light.shape[0])/25.\n",
    "    temp = light-light.mean(0)\n",
    "    plt.plot(t_led, temp/50., c='red')\n",
    "\n",
    "    # plot mic ttl pulse\n",
    "    mic4_subsampled = mic4[::10]\n",
    "    t_mic = np.arange(mic4_subsampled.shape[0])/12500.\n",
    "    temp = mic4_subsampled-mic4_subsampled.mean(0)\n",
    "    plt.plot(t_mic, temp+2.8,c='blue')\n",
    "\n",
    "    # formating\n",
    "    plt.title(\"LED: red;   TTL Pulse: Blue\", fontsize=20)\n",
    "    plt.xlim(0,1200)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Time (sec)\",fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: PLOT THE DISTRIBUTION OF DISTANCES BETWEEN LED LIGHT AND TTL AUDIO\n",
    "# THIS WILL INDICATE WHETHER STRETECHING OF DATA Is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000000,)\n"
     ]
    }
   ],
   "source": [
    "mic0 = np.load('/media/cat/4TBSSD/dan/july_19/2020_07_24_15_11_26_425064/audio/2020_07_24_15_11_26_425064_audio_mic_0.npy')\n",
    "print (mic0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422.98 423.08 sec\n",
      "10574\n"
     ]
    }
   ],
   "source": [
    "nfft = 1024\n",
    "fs_audio = 125000\n",
    "fs_camera = 25\n",
    "\n",
    "start = int((400.98+8.7+1.4+9.08+2.47+0.35)*fs)\n",
    "end = int(start+.1*fs)\n",
    "\n",
    "print (start/fs, end/fs, 'sec')\n",
    "\n",
    "ax=plt.subplot(1,2,1)\n",
    "pxx, freqs, bins, im = specgram(mic0[start:end], NFFT=nfft, Fs=fs, noverlap=nfft/2,\n",
    "                                       clim=(-120,-60))\n",
    "plt.title(\"Start: \"+str(start/fs_audio)+ \" end: \"+str(end/fs_audio)+\" sec\")\n",
    "# \n",
    "ax=plt.subplot(1,2,2)\n",
    "frame_id_camera = int(start/fs*fs_camera)\n",
    "print (frame_id_camera)\n",
    "plt.imshow(vid[frame_id_camera])\n",
    "plt.title(\"Frame: \"+str(frame_id_camera))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '/media/cat/4TBSSD/dan/july_19/2020_07_24_15_11_26_425064/snippets/2020_07_24_15_11_26_425064_snippet_'\n",
    "\n",
    "snippet=9\n",
    "np.savez(fname+str(snippet), \n",
    "        usv = mic0[start:end],\n",
    "        frame = vid[frame_id_camera],\n",
    "        time_start_sec = start,\n",
    "        time_end_sec = end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[520 780 520 780]\n",
      "Loading:  E:\\july10_pos8A\\audio\\2020-07-10_20_05_40.673203_audio.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:211: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos8B\\audio\\2020-07-10_20_06_22.532042_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos8C\\audio\\2020-07-10_20_07_19.409833_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos8D\\audio\\2020-07-10_20_08_02.677607_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos8E\\audio\\2020-07-10_20_09_07.645162_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos1\\audio\\2020-07-10_20_01_52.787211_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos5\\audio\\2020-07-10_20_03_05.256554_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos11\\audio\\2020-07-10_20_04_20.196753_audio.npy\n",
      "len r2 array:  4\n",
      "Loading:  E:\\july10_pos15\\audio\\2020-07-10_20_03_42.148538_audio.npy\n",
      "len r2 array:  4\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE SHIFT CORRELATION AND FIT POLYNOMIAL\n",
    "\n",
    "mics = read_filter_data(fname, call_onsets[ctr],call_offsets[ctr], filter_data, plotting)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bandpass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "start_fs = 6500\n",
    "end_fs = 7500\n",
    "mic0_audio_bp = butter_bandpass_filter(mic0_audio, start_fs, end_fs, fs)  # YOU CAN AUTODETECT THIS\n",
    "mic1_audio_bp = butter_bandpass_filter(mic1_audio, start_fs, end_fs, fs)\n",
    "mic2_audio_bp = butter_bandpass_filter(mic2_audio, start_fs, end_fs, fs)\n",
    "mic3_audio_bp = butter_bandpass_filter(mic3_audio, start_fs, end_fs, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'mic1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,3))\n",
    "ax=plt.subplot(1,1,1)\n",
    "plt.plot(call_mic0_bp, 'k', markersize=1)\n",
    "#plt.title('mic0')\n",
    "\n",
    "#plt.figure(figsize=(20,3))\n",
    "#ax=plt.subplot(2,1,2)\n",
    "plt.plot(call_mic1_bp, 'r', markersize=1)\n",
    "plt.title('mic1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
